{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from libnlp import preprocessing\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader,Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Jamiu Afolabi/.cache\\torch\\hub\\huggingface_pytorch-transformers_master\n",
      "Using cache found in C:\\Users\\Jamiu Afolabi/.cache\\torch\\hub\\huggingface_pytorch-transformers_master\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if '../' not in sys.path:\n",
    "    sys.path.append('../')\n",
    "\n",
    "class Env:\n",
    "    def __init__(self,tokenizer_model='bert-base-multilingual-uncased',max_len=120,seed=42):\n",
    "        \n",
    "        #Defining the paths\n",
    "        self.data_path='../Data'\n",
    "        self.train_path='Train.csv'\n",
    "        self.test_path='Test.csv'\n",
    "        self.ppd_path='../ppd'\n",
    "        \n",
    "        #Definining the tokenizer\n",
    "        self.tokenizer=torch.hub.load('huggingface/pytorch-transformers', 'tokenizer',tokenizer_model )\n",
    "        self.model=torch.hub.load('huggingface/pytorch-transformers', 'model',tokenizer_model )\n",
    "        self.tokenizer_max_len=max_len\n",
    "        self.cls_token=self.tokenizer.cls_token_id\n",
    "        self.sep_token=self.tokenizer.sep_token_id\n",
    "        self.pad_token=self.tokenizer.pad_token_id\n",
    "        self.unk_token=self.tokenizer.unk_token_id\n",
    "        \n",
    "        #Setting the Seed Value\n",
    "        if torch.cuda.is_available():\n",
    "            self.device='cuda'\n",
    "        else:\n",
    "            self.device='cpu'\n",
    "        torch.manual_seed(seed)\n",
    "        os.environ['PYTHONHASHSEED']=str(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic=True\n",
    "        torch.backends.cudnn.benchmark=False\n",
    "E=Env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArabiziDataset(Dataset):\n",
    "    def __init__(self,df,tokenizer,max_len,train=True):\n",
    "        self.train=train\n",
    "        self.tokenizer=tokenizer\n",
    "        self.max_len=max_len\n",
    "        self.text=df.text.values\n",
    "        self.labels=df.label.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)  \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        token,mask,len_token=self.token_mask(self.text[idx],self.max_len)\n",
    "        if self.train:\n",
    "            label=self.labels[idx]\n",
    "            return token,mask,len_token,label\n",
    "        return token,mask,None\n",
    "    def token_mask(self,text,max_len):\n",
    "        if max_len in range(511,513):\n",
    "            len_text=min(max_len-2,len(text))\n",
    "        else:\n",
    "            len_text=min(max_len,len(text))\n",
    "        text=text[:len_text]\n",
    "        token=self.custTokenizer(self.tokenizer,text)\n",
    "        len_token=len(token)\n",
    "        mask= [1] * len_token\n",
    "        return token,mask,len_token\n",
    "    \n",
    "    def custTokenizer(self,tokenizer,text):\n",
    "        return tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Custom Padding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customPadding(batch,tokenizer=E.tokenizer):\n",
    "    comp=list(zip(*batch))\n",
    "    tokens=comp[0]\n",
    "    masks=comp[1]\n",
    "    len_tokens=comp[2]\n",
    "    labels=comp[3]\n",
    "    max_len=max(len_tokens)\n",
    "    tokens_ret=[]\n",
    "    masks_ret=[]\n",
    "    \n",
    "    for idx in range(len(tokens)):\n",
    "        pad_len=max_len-min(len_tokens[idx],max_len)\n",
    "        padding=[tokenizer.pad_token_id] * pad_len\n",
    "        token=tokens[idx] + padding\n",
    "        mask=masks[idx] + [0] * pad_len\n",
    "        tokens_ret.append(token)\n",
    "        masks_ret.append(mask)\n",
    "        \n",
    "    if len(comp)==4:\n",
    "        return torch.tensor(tokens_ret),torch.tensor(masks_ret),torch.tensor(labels)\n",
    "    return torch.tensor(tokens_ret),torch.tensor(masks_ret)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E.tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(os.path.join(E.ppd_path,E.train_path),encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=ArabiziDataset(train_df,E.tokenizer,E.tokenizer_max_len)\n",
    "train_loader=DataLoader(train_ds,batch_size=10,collate_fn=customPadding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter=iter(train_loader)\n",
    "a,b,c=dataiter.next()\n",
    "e,f,g=dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 32332, 10112, 17675, 11301, 13934,   165, 32332, 10112, 10238,\n",
       "         13871, 64265, 89882, 11055, 10243, 10243, 11435, 13228,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [  101, 10816, 15390, 10900, 13871, 10277, 37521, 10537, 50945, 10408,\n",
       "         15643, 13533, 12364, 15235, 10102, 12854, 14382, 10421, 10481, 12620,\n",
       "         28230,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [  101, 59878, 25403, 10167, 11162, 49715, 10165, 39407, 10911, 10863,\n",
       "         42912, 85904, 10159, 28204, 83863, 11638, 33114, 26658, 40914, 13216,\n",
       "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [  101, 10117, 43009, 15930, 66813, 12645, 11587, 12314, 11695, 10709,\n",
       "         17675, 87694, 15398, 14795, 10150, 13922, 10117, 11052, 67069, 10709,\n",
       "         19368, 10911, 11587, 11581, 23097, 17272, 33812, 10346, 11695, 22079,\n",
       "         10117, 13110, 20651, 48399, 14801, 13922, 10117,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [  101, 10678, 94637, 10112, 17272,   165, 15440, 10240,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [  101, 54017,   130, 18159, 15707, 10107, 48890, 11880, 10959, 10123,\n",
       "         10167,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [  101, 47237, 11880, 10953, 51333, 50584, 11695,   130, 71816, 15095,\n",
       "         14519, 10163,   126, 20204, 10163, 50584, 11695, 10953, 31238, 12979,\n",
       "         10546, 11301, 10408, 11518, 69078, 10117, 67626, 10112, 10391, 56520,\n",
       "         24808, 10507, 11301, 12633, 10277, 10593, 11301, 10330,   128, 11911,\n",
       "         17439, 10425, 11444, 13533, 10546,   102],\n",
       "        [  101, 10152, 28625, 13921,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [  101, 83747, 10417, 31933, 49071, 10167, 13571, 33508, 11947, 10275,\n",
       "         13533, 45052, 17272, 10678,   165, 56195, 64246, 10112, 12268, 13209,\n",
       "           124, 10335, 54203, 10745, 18092, 66032, 12667, 10507, 39163, 11839,\n",
       "         10131,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0],\n",
       "        [  101, 57338, 10337, 49878, 11763, 10117, 12013, 10553, 24764, 11032,\n",
       "         22079, 12314, 10959, 10390, 41755, 10283, 10417, 11088, 10687, 11544,\n",
       "         10132, 10562, 10117,   124, 10785, 10131, 26642, 11717, 11763, 10106,\n",
       "         14302, 41796, 16450, 37079, 10889, 10112, 11518, 18159, 41755, 11226,\n",
       "         14782, 55773, 10425,   102,     0,     0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-cd1925d5b88b>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-cd1925d5b88b>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    self.bert_model=\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class BertModel(nn.Module):\n",
    "    def __init__(self,n_outputs,bert_model=E.model):\n",
    "        super(BertModel,self).__init__()\n",
    "        self.K=n_outputs\n",
    "        self.bert_model=E.model\n",
    "        self.bert_hidden_size=E.model.config.hidden_size\n",
    "        \n",
    "        self.conv1=nn.Conv1d(self.bert_hidden_size,32,3,padding=1)\n",
    "        self.pool1=nn.MaxPool1d(2)\n",
    "        self.conv2=nn.Conv1D(32,64,4,padding=1)\n",
    "        self.pool2=nn.MaxPool1d(2)\n",
    "        self.conv3=nn.Conv1D(63,128,5,padding=1)\n",
    "        self.pool3=nn.MaxPool1d(2)\n",
    "        self.conv3=nn.Conv1d(126,256,3,padding=1)\n",
    "        \n",
    "        self.fc1=nn.Linear(256,128)\n",
    "        self.fc2=nn.Linear(128,self.K)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        out=self.bert_model(X)\n",
    "        out=out.permute(0,2,1)\n",
    "        out=\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
